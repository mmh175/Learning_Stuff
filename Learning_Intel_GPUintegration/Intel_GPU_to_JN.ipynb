{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d23860f-edad-411f-ac84-097dba213dbd",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "---\n",
    "- 🧩 Intel OpenAPI Base Toolkit:\n",
    "\n",
    " > ➡️ [https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html]\n",
    "\n",
    "---\n",
    "- 🧩 Python Package:\n",
    "\n",
    " > ⚡`dpctl` — Data Parallel Control : `pip install dpctl`\n",
    "\n",
    " > ⚡`dpnp` — Data Parallel NumPy : `pip install dpnp`\n",
    "\n",
    " > ⚡`numba-dpex` — Numba Data Parallel Extension : `pip install -i https://pypi.anaconda.org/dppy/label/dev/simple numba-dpex`\n",
    "\n",
    " > ⚡`scikit-learn-intelex` — Intel Extension for scikit-learn : `pip install scikit-learn-intelex`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab4b29-a189-433e-b1fb-03cdfe37610e",
   "metadata": {},
   "source": [
    "### 🧩 `dpctl` — Data Parallel Control\n",
    "\n",
    "🔧 A Python interface to SYCL (C++ parallel programming model).  \n",
    "🖥️ Enables control over devices (CPU, GPU) and execution queues.  \n",
    "📦 Useful for managing low-level data-parallel operations.\n",
    "\n",
    "➡️ [PyPI link](https://pypi.org/project/dpctl/)  \n",
    "➡️ [GitHub](https://github.com/IntelPython/dpctl)\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 `dpnp` — Data Parallel NumPy\n",
    "\n",
    "📊 A NumPy-compatible library for accelerated array operations.  \n",
    "⚡ Drop-in replacement for NumPy using SYCL under the hood.  \n",
    "🎯 Run NumPy-like code on Intel GPUs and CPUs without rewriting.\n",
    "\n",
    "➡️ [PyPI link](https://pypi.org/project/dpnp/)  \n",
    "➡️ [GitHub](https://github.com/IntelPython/dpnp)\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ `numba-dpex` — Numba Data Parallel Extension\n",
    "\n",
    "🚀 Enables JIT-compiled Python kernels for SYCL devices (like Intel GPUs).  \n",
    "🧠 Extends Numba's syntax to support `@kernel` and `@dpjit` decorators.  \n",
    "💡 Write CUDA-style parallel loops in Python!\n",
    "\n",
    "➡️ [PyPI link](https://pypi.org/project/numba-dpex/)  \n",
    "➡️ [GitHub](https://github.com/IntelPython/numba-dpex)\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 `scikit-learn-intelex` — Intel Extension for scikit-learn\n",
    "\n",
    "📈 Accelerates `scikit-learn` estimators using Intel oneAPI Data Analytics Library (oneDAL).  \n",
    "🧪 Improves training/prediction time significantly on Intel hardware.  \n",
    "✅ Plug-and-play: just import and patch!\n",
    "\n",
    "```python\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae6c14-4839-4234-a331-a65ff7455c12",
   "metadata": {},
   "source": [
    "# Check if the GPU is connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9a912b9-a29c-4e48-b510-53b04c1a4748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dpctl is installed — version: 0.19.0\n",
      "✅ dpnp is installed — version: 0.17.0\n",
      "⚠️ numba-dpex is installed but failed to get version — DLL load failed while importing _dpexrt_python: The specified module could not be found.\n",
      "✅ scikit-learn is installed — version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "packages = {\n",
    "    \"dpctl\": \"dpctl\",\n",
    "    \"dpnp\": \"dpnp\",\n",
    "    \"numba-dpex\": \"numba_dpex\",\n",
    "    \"scikit-learn\": \"sklearn\"\n",
    "}\n",
    "\n",
    "for name, module in packages.items():\n",
    "    spec = importlib.util.find_spec(module)\n",
    "    if spec is not None:\n",
    "        try:\n",
    "            mod = importlib.import_module(module)\n",
    "            version = getattr(mod, \"__version__\", \"version not found\")\n",
    "            print(f\"✅ {name} is installed — version: {version}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {name} is installed but failed to get version — {e}\")\n",
    "    else:\n",
    "        print(f\"❌ {name} is NOT installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c990f09-31d7-4a4f-9c0e-a555a0484884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️ Device: Intel(R) Arc(TM) B580 Graphics\n",
      "🔧 Backend: backend_type.level_zero\n",
      "🚀 Is GPU: True\n",
      "===\n",
      "🖥️ Device: Intel(R) Arc(TM) B580 Graphics\n",
      "🔧 Backend: backend_type.opencl\n",
      "🚀 Is GPU: True\n",
      "===\n",
      "🖥️ Device: AMD Ryzen 7 5700G with Radeon Graphics         \n",
      "🔧 Backend: backend_type.opencl\n",
      "🚀 Is GPU: False\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "import dpctl\n",
    "\n",
    "for device in dpctl.get_devices():\n",
    "    print(\"🖥️ Device:\", device.name)\n",
    "    print(\"🔧 Backend:\", device.backend)\n",
    "    print(\"🚀 Is GPU:\", device.is_gpu)\n",
    "    print(\"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f966afcb-27dc-42b7-bfa6-67d1b78fb335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dpnp imported successfully.\n",
      "a (dpnp): [0 1 2 3 4 5 6 7 8 9]\n",
      "b (dpnp): [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "a + b: [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "✅ dpnp computation ran without error.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import dpnp\n",
    "    print(\"✅ dpnp imported successfully.\")\n",
    "\n",
    "    a = dpnp.arange(10)\n",
    "    b = dpnp.ones(10)\n",
    "    c = a + b\n",
    "\n",
    "    print(\"a (dpnp):\", a)\n",
    "    print(\"b (dpnp):\", b)\n",
    "    print(\"a + b:\", c)\n",
    "\n",
    "    print(\"✅ dpnp computation ran without error.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ dpnp is NOT working properly:\")\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4722545-9fc4-4cd5-85c2-bc28a7c43305",
   "metadata": {},
   "source": [
    "# CPU vs GPU Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d18cba3-14f1-41de-b9ca-80a01a116697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 NumPy (CPU) Time: 0.120 sec\n",
      "🚀 dpnp (GPU) Time: 0.023 sec\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dpnp\n",
    "import dpctl\n",
    "import time\n",
    "\n",
    "# CPU (numpy)\n",
    "size = 100_000_000\n",
    "a_cpu = np.ones(size, dtype=np.float32)\n",
    "b_cpu = np.ones(size, dtype=np.float32)\n",
    "\n",
    "start_cpu = time.time()\n",
    "c_cpu = a_cpu + b_cpu\n",
    "end_cpu = time.time()\n",
    "print(f\"🧠 NumPy (CPU) Time: {end_cpu - start_cpu:.3f} sec\")\n",
    "\n",
    "# GPU (dpnp + Intel GPU)\n",
    "device = dpctl.SyclDevice(\"level_zero:gpu\")\n",
    "queue = dpctl.SyclQueue(device)\n",
    "\n",
    "a_gpu = dpnp.ones(size, dtype=dpnp.float32, sycl_queue=queue)\n",
    "b_gpu = dpnp.ones(size, dtype=dpnp.float32, sycl_queue=queue)\n",
    "\n",
    "start_gpu = time.time()\n",
    "c_gpu = a_gpu + b_gpu\n",
    "end_gpu = time.time()\n",
    "print(f\"🚀 dpnp (GPU) Time: {end_gpu - start_gpu:.3f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea258b87-8383-4463-84fe-afc924375b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Repeating 50 matrix multiplications of 4096x4096\n",
      "🧠 NumPy (CPU) Time: 10.56 sec\n",
      "🚀 dpnp (GPU) Time: 0.55 sec\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dpnp\n",
    "import dpctl\n",
    "import time\n",
    "\n",
    "# Settings\n",
    "n = 4096        # Matrix size (4096x4096)\n",
    "repeats = 50    # Number of times to multiply\n",
    "\n",
    "print(f\"🔁 Repeating {repeats} matrix multiplications of {n}x{n}\")\n",
    "\n",
    "# 🧠 CPU (NumPy)\n",
    "A_cpu = np.random.rand(n, n).astype(np.float32)\n",
    "B_cpu = np.random.rand(n, n).astype(np.float32)\n",
    "\n",
    "start_cpu = time.time()\n",
    "for _ in range(repeats):\n",
    "    C_cpu = A_cpu @ B_cpu\n",
    "end_cpu = time.time()\n",
    "print(f\"🧠 NumPy (CPU) Time: {end_cpu - start_cpu:.2f} sec\")\n",
    "\n",
    "# 🚀 GPU (dpnp + Intel Arc via Level-Zero)\n",
    "device = dpctl.SyclDevice(\"level_zero:gpu\")\n",
    "queue = dpctl.SyclQueue(device)\n",
    "\n",
    "A_gpu = dpnp.array(A_cpu, sycl_queue=queue)\n",
    "B_gpu = dpnp.array(B_cpu, sycl_queue=queue)\n",
    "\n",
    "start_gpu = time.time()\n",
    "for _ in range(repeats):\n",
    "    C_gpu = A_gpu @ B_gpu\n",
    "end_gpu = time.time()\n",
    "print(f\"🚀 dpnp (GPU) Time: {end_gpu - start_gpu:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab47508-0a57-4ab4-87d6-826e608f9f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeating 500 matrix multiplications of 4096x4096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NumPy CPU: 100%|█████████████████████████████████████████████████████████████████████| 500/500 [01:49<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy (CPU) Time: 109.42 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dpnp GPU: 100%|█████████████████████████████████████████████████████████████████████| 500/500 [00:04<00:00, 103.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpnp (GPU) Time: 4.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dpnp\n",
    "import dpctl\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Settings\n",
    "n       = 4096        # Matrix size (4096x4096)\n",
    "repeats = 500    # Number of times to multiply\n",
    "\n",
    "print(f\"Repeating {repeats} matrix multiplications of {n}x{n}\")\n",
    "\n",
    "# CPU (NumPy)\n",
    "A_cpu = np.random.rand(n, n).astype(np.float32)\n",
    "B_cpu = np.random.rand(n, n).astype(np.float32)\n",
    "\n",
    "start_cpu = time.time()\n",
    "for _ in tqdm(range(repeats), desc=\"NumPy CPU\"):\n",
    "    C_cpu = A_cpu @ B_cpu\n",
    "end_cpu = time.time()\n",
    "print(f\"NumPy (CPU) Time: {end_cpu - start_cpu:.2f} sec\")\n",
    "\n",
    "# GPU (dpnp + Intel Arc via Level-Zero)\n",
    "device = dpctl.SyclDevice(\"level_zero:gpu\")\n",
    "queue = dpctl.SyclQueue(device)\n",
    "\n",
    "A_gpu = dpnp.array(A_cpu, sycl_queue=queue)\n",
    "B_gpu = dpnp.array(B_cpu, sycl_queue=queue)\n",
    "\n",
    "start_gpu = time.time()\n",
    "for _ in tqdm(range(repeats), desc=\"dpnp GPU\"):\n",
    "    C_gpu = A_gpu @ B_gpu\n",
    "end_gpu = time.time()\n",
    "\n",
    "print(f\"dpnp (GPU) Time: {end_gpu - start_gpu:.2f} sec\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(intelARC)",
   "language": "python",
   "name": "intelarc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
